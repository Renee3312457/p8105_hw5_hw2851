---
title: "hw5"
author: "Renee Wang UNI:hw2851"
date: "11/20/2021"
output: github_document
---

---
title: "Homework 5"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(rvest)
library(stringr)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("","Unknown")) %>%
  mutate(city_state = str_c(city, state),
         resolution = case_when(
              disposition == "Closed without arrest" ~ "unsolved",
              disposition == "Open/No arrest"        ~ "unsolved",
              disposition == "Closed by arrest"      ~ "solved")) %>%
  relocate(city_state) %>%
  filter(city_state != "Tulsa_AL")
```

```{r}
baltimore_df =
  homicide_df %>%
  filter(city_state == "BaltimoreMD")

baltimore_summary =
  baltimore_df %>%
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

baltimore_test =
  prop.test(
    x = baltimore_summary %>% pull(unsolved),
    n = baltimore_summary %>% pull(n))
```
The estimated proportion of unsolved homicides and confidence intervals for Baltimore can be found below:
```{r}
baltimore_test %>%
  broom::tidy()  
```

# Problem2
```{r}
# read all data files
prob_2_data =
 tibble(
  filename = list.files("./data/zip_data/"))

# build a function that read file content
readcsv = function(csv, path="./data/zip_data"){
 paste(path,csv,sep="/")  %>%
   read.csv()}

prob_2_data =
  prob_2_data %>%
  mutate(raw_results = map(prob_2_data$filename, readcsv)) %>%
  # unnest for easier plot
  unnest(raw_results) %>%
  # remove .csv part
  mutate(filename_wo_extension = map_chr(.x = filename, ~ unlist(str_split(.x, "\\.") )[[1]] ) ) %>%
  # split by '_' to extract arm and subject id
  mutate(arm = map_chr(.x = filename_wo_extension, ~ unlist(str_split(.x, "_") )[[1]] )) %>%
  mutate(subject_id = map_chr(.x = filename_wo_extension, ~ unlist(str_split(.x, "_") )[[2]] ))

# create a pivoted version to make plotting easier
prob_2_data_pivoted =
  prob_2_data %>%
  pivot_longer(week_1:week_8,
               names_to = "week",
               names_prefix = "week_",
               values_to = "value") %>%
  mutate(week = as.integer(week))
prob_2_plot =
  prob_2_data_pivoted %>%
  group_by(filename_wo_extension) %>%
  ggplot(aes(x = week, y = value, color = interaction(arm, subject_id))) +
    geom_line()

prob_2_plot
```

The plot above shows the observation values on each subject over time. It seems that the exp group generally has higher observation values than the control group; no apparent temporal trend can be observed.

# Problem 3
We first load the iris dataset and introduce missing values:
```{r}

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

Then we implement the function that replaces missing values, and apply on the iris_with_missing dataset:
```{r}

# fill in missing value for a single value
fill_missing_value = function(val, default_val) {
  if (is.na(val)) {
    default_val
  }
  else {
    val
  }
}

fill_missing_values = function(vec) {
  if (length(vec) <= 0) {
    stop("Error: not a valid vector")
  }
  
  # check if it's numeric vector
  if (is.numeric(vec)) {
    # fill in with mean
    mean_value = mean(vec, na.rm = TRUE)
    map(.x = vec, ~ fill_missing_value(.x, mean_value))
  }
  else if(is.character(vec)) {
    # fill in with "virginica"
    map(.x = vec, ~ fill_missing_value(.x, "virginica"))
  }
}

output = vector("list", length = 5)
output = map(iris_with_missing, fill_missing_values)
```